

# 🧩 선착순 이벤트 처리 구조 개선기
상황 : 웹사이트 페이지를 방문할 때마다 (ip, url,  시간대) 등 방문기록이 DB테이블에 insert 될때,

1. 선착순 이벤트로 특정 시간에 사용자가 몰릴때 RDB테이블에 짧은 타임에
과도한 insert로 예측되는 문제를 설명하고
2. 해결 방법을 제시
   
### 1️⃣ 문제 상황 

기존에는 **톰캣 스레드(Tomcat thread)** 가

* `손님 응대(이벤트 페이지 로직)`
* `주방 작업(DB insert 로직)`
  을 **모두 직접 처리**하고 있었다.

이때 선착순 이벤트가 열리면 특정 테이블(예: `event_entry`)에
`INSERT` 작업이 폭주하여 **B-Tree 인덱스의 리프 노드 페이지에 락 경쟁**이 발생한다.

* 첫 번째 `INSERT` 작업만 락을 획득하고 수행
* 나머지 `INSERT`들은 **DB 커넥션을 점유한 채 대기 상태**로 머무름
* 그 사이 새로운 `SELECT` 요청(다른 API 호출)이 들어와도
  DB 커넥션 풀에 여유가 없어 **커넥션을 얻지 못하고 대기**
* 결국 **서버 전체가 멈춘 듯한 상태**에 빠짐

즉,

> 톰캣 스레드가 ‘요리(INSERT)’하느라 ‘손님 응대(SELECT)’로 돌아가지 못한 상황이었다. 🍳

---

### 2️⃣ 문제 인식

톰캣 스레드가 동시에

* 주방(DB 작업)
* 홀(사용자 응답)
  을 둘 다 맡으니, 한쪽이 막히면 전체가 정체되는 구조였다.
  이를 해결하기 위해 **역할을 분리**해야 했다.

---

## 3️⃣ 해결 방법 — 솔루션  A : 큐(Queue)와 워커스레드(Worker Thread) 도입

💥 선착순 이벤트 폭주 시 발생 순서

1. 핫스팟 발생: INSERT가 DB 인덱스(B-Tree)의 마지막 리프 노드 페이지("1번 화구")에 몰림
2. 락 점유: "사장님 1"이 "1번 화구"(Lock)를 잡고 요리를 시작
3. 커넥션 고갈: "사장님 2~10"은 락이 풀리길 기다리며 DB 커넥션(냄비) 을 쥔 채 대기
4. 커넥션 풀 소진: "냄비 선반(DB 커넥션 풀)"은 0/10 상태로 고갈
5. 연쇄 붕괴 시작: INSERT와 무관한 SELECT API("샐러드 손님") 도착
6. "사장님 11"은 커넥션이 없어 작업 시작조차 불가
7. 결과: INSERT의 병목이 SELECT까지 마비시키는 연쇄 붕괴 발생

문제의 본질: "사장님(톰캣 스레드)"이 "느린 주방 일(DB 작업)"을 기다리느라
"냄비(DB 커넥션)"를 반납하지 못하고, "빠른 손님 응대(다른 API)"로 돌아가지 못하는 구조적 문제
**핵심 아이디어:**

> 톰캣 스레드는 DB 작업을 직접 하지 않고, “주문서만 큐에 올려두고” 바로 손님에게 응답한다.

1. **톰캣 스레드**

   * 사용자의 `insert` 요청을 받으면,
     작업 내용을 **큐(Queue)** 에 넣고 **즉시 응답** 반환.
   * 따라서 사용자 응답 속도 저하 없이 빠르게 처리 가능.

2. **워커스레드(Worker Thread)**

   * 큐에 쌓인 작업들을 순서대로 꺼내 DB에 반영
   * 각 작업은

     * 커넥션풀에서 커넥션을 **획득 → insert → 반납**
     * 그 다음 작업으로 이동
   * 예를 들어 **워커스레드 1개만** 두면,
     커넥션을 한 번에 하나씩만 사용하므로
     DB 커넥션풀 고갈 문제 해결 ✅

---

### 3️⃣-1 결과

| 문제        | 개선 전                     | 개선 후                |
| --------- | ------------------------ | ------------------- |
| DB 커넥션 고갈 | 여러 톰캣 스레드가 동시에 insert 대기 | 워커 1개가 순차 insert 처리 |
| 사용자 응답 지연 | insert 완료까지 톰캣 스레드 대기    | 큐에 맡기고 즉시 응답        |
| 서버 전체 정체  | insert로 인한 커넥션 점유        | 커넥션 사용 최소화          |

---

### 3️⃣-2 남은 과제

큐로 인해 **DB 커넥션 문제**는 해결되었지만,
여전히 `INSERT` 대상 인덱스 리프 노드가 집중되는 **핫스팟(Hotspot) 병목**은 남아 있다.

또한 `SELECT` 요청은 작업특성상 큐를 타지 않기 때문에,
만약 조회 쿼리 자체가 특정 리소스에 집중되는 경우는 어떻게 할까


> 톰캣 스레드가 “모든 걸 직접 처리하는 구조”에서
> “큐와 워커스레드로 역할을 분리한 구조”로 바꾸면서
> 응답성 문제와 DB 커넥션 고갈을 효과적으로 해결했다.
---
이후에는 **DB 인덱스 병목 완화**와
**읽기(SELECT) 트래픽 분산 전략**이 다음 단계 과제로 이어진다.

### ✅ 솔루션 A에 대한 내 고민들과 딥다이브

select작업이 일반적으로 빠른작업으로 알려져있지만, **느린 select작업이라면? select 핫스팟이 일어나면?**
elect 작업와 insert 작업의 작업성격의 차이가 존재하기때문에
톰캣스레드는 두 종류의 작업을 다르게 대한다.
select 작업은 데이터를 저장하는게 아니라 요청하는 작업이기에 큐에 들어가지 않는다.
그럼 select 핫스팟이 일어나면 큐로는 못해결하겠네. 그럼어떻게하지라는 고민.


<링크>

**반드시 큐 자료구조여야만 할까? 다른 자료구조가 대체 혹은 더 뛰어난 성능을 가지진 않을까? vs..**  
<링크>
**db커넥션풀 갯수??**

---
## 솔루션 A의 한계
<사진첨부>

## 4️⃣ 해결 방법 — 솔루션  B: BATCH
큐 주문서 꽂이에 대하여 워커스레드가 처리하는 방식을 바꾼다. 기존에는 insert작업이 큐에 들어오면 워커스레드가 db커넥션 획득 (가스밸브 오픈)- db insert작업 한개 처리 - db커넥션 반납 이 과정의 반복이였다.
그래서 생산자속도(카운터직원인 톰캣스레드)를 소비자속도(주방요리사인 워커스레드)가 따라가지 못해 큐에 작업에 계속 쌓이는 문제가 발생했다.
spring 프레임워크의 jdbctemplate기술을 이용해 워커스레드가 한개씩 처리하는게 아니라 n개씩 처리하게 만든다.
한번 db커넥션을 획득하여 초대형찜기(batchUpdate)를 이용해 만두1000개(insert작업 1000개)를 한번에 처리한다.


**batch_size 튜닝을 몇으로 해야 최적일까 ?**
->라는 고민은 할 지금 필요가 없어졌다.

log를 살펴보면 999개를 넘는게 없다. 한번에 처리할때 999개를 처리했다는 로그가 있어야. batch_size를 늘려서 tps를 더 최적화하거나 해볼텐데..
솔루션a보다 에러는 줄었다.

로그 샘플 10개 추출

V2보다 TPS가 10배 이상상 빨라졌다.
그중 한개를 보자.
[V3 BATCH] 377개의 로그 처리완료. 총시간: 255ms
계산: (377 / 255) * 1000 = 1,478 TPS 
1,573 TPS 생산자(카운터직원)속도
1,478 TPS 소비자(주방요리사)속도



1초마다 약 73개씩 "주문서"가 큐에 "계속 쌓여서", 결국 V2와 똑같이 **"느린 GC Hell"**이 발생했고, "손님(nGrinder)"이 **0.9%**만큼 **"Timeout(포기)"**한 겁니다.


<img width="802" height="367" alt="image" src="https://github.com/user-attachments/assets/ebe1e857-3792-4e1c-9b6d-b1ebaeaf5113" />

라고 결론내릴수있을까?

**로그 WORST CASE 샘플 추출**
[가장 운이 나쁠 때 (Worst-Case)]

[V3 BATCH] 12개의 로그 처리완료. 총시간: 83ms

계산: (12 / 83) * 1000 = 144 TPS

(V2(save) 때와 속도가 똑같습니다! "1000인용 찜기"로 "만두 12개"를 찌는 낭비를 한 겁니다.)
V2에 비해서 V3에서 에러율이 감소한것은 유의미한 결과라고 볼수있다.

V3가 V2보다 "1개 이상씩(Batch)" 처리했기 때문에, "비싼 비용(커넥션)"을 아낄 수 있었고, 그 결과 "요리사"의 **"평균 속도"**가 V2(142 TPS)보다 V3(778 TPS)가 훨씬 빨라짐.
그러나 WORST_CASE에 따르면 초당 처리량TPS이 유의미하게 향상되었다고는 볼수없다.
그럼 어떻게 해야할까.

V1(즉사) ➔ V2(큐) ➔ V3(배치)로 "해결"한 줄 알았지만, 그건 "해결"이 아니라 **"완화"**였습니다.

이상치의 함정인것인가?... tps는 향상된것이 아닐까? worst_Case(tps 144. v2와 비슷)는 왜 일어났고, 어떻게 해야해야하띾?

worst case가 나온 이유는 무엇일까? v2에 비해 문제가 완전히 해결되었다고 보긴 어려운상황.
v1으로 돌아가 db락 문제(핫스팟)를 건드려야하는것인가?
아니면 gc hell 문제를 건드려야 하는것인가?

______________________________________
4️⃣-B. "Error 0.9%"의 진짜 범인 찾기: DB 락 vs GC Hell
1. 첫 번째 가설 (Hypothesis A): "DB 락(핫스팟)"
V3 테스트 결과, Error 0.9%가 발생.

"요리 개수"와 "총 시간"이 비례하지 않는 **"이상 로그"**를 발견함.

[증거 A-1] 54개 처리 ➔ 260ms
[증거 A-2] 377개 처리 ➔ 255ms
[1차 결론] "요리 개수"와 상관없이 "0.25초"의 **"고정 락(DB 락)"**이 걸린다고 "추정"함. (V1의 핫스팟이 범인?-> pk에 걸려있던 인덱스를 uuid로 변경하는등의 방법을 고려?)

2. 가설 A의 "폐기" (반박 증거 발견)
하지만(But), "전체 로그"를 다시 분석하자 "가설 A"를 **"완벽하게 반박"**하는 **"초고속 로그"**가 발견됨.

[반박 증거 B-1] 80개 처리 ➔ 16ms (0.016초)
[반박 증거 B-2] 5개 처리 ➔ 16ms

[2차 결론] "DB 락"은 "범인"이 아님. (락이 있다면 "16ms"가 절대 불가능함.)

3. "진짜 범인" (Hypothesis B): "GC Hell (Stop-the-World)"
우리는 "두 개의 얼굴"을 가진 서버를 발견함.

"평소 (얼굴 1)": ~16ms로 "초고속"으로 작동함. (TPS 5,000)
"가끔 (얼굴 2)": ~250ms로 "멈춤".
"카운터(1573)"보다 "요리사(5000)"가 "훨씬 빠른데도" Error 0.9%가 뜸.
[최종 결론] 이 "모든 증거"를 설명할 범인은 **"GC Hell"**뿐.

"카운터"와 "요리사" 스레드 "모두"가 **"GC(Stop-the-World)"**에 **"0.25초간 '얼음'"**이 되면서, nGrinder(손님)는 "Timeout(Error 0.9%)"을 뱉고, "요리사"는 "250ms 멈춤 로그"를 남긴 것임.

4. 다음 단계 (V4)
"UUID(DB 락)"는 "가짜 보스"였음을 "데이터"로 증명함.

이 "GC Hell" 가설을 증명하기 위해, **jstat**을 이용해 "Full GC"가 0.25초씩 발생하는지 "측정"하기로 함.



================================
2. "Crucial" (README "본문"에 "반드시" 녹여낼 고민)
이 "고민"들은 님의 "V1 ➔ V4" 스토리의 "클라이맥스" 그 자체입니다.

"UUID에 인덱스를 걸면?" (DB 락 가설):
(Crucial) 이건 "딥다이브"가 아닙니다. 님의 README "3. 튜닝 여정 ➔ 3️⃣ V3" 섹션의 "가장 중요한" "하이라이트"입니다.
녹이는 법: (제가 "최종 템플릿"으로 드린 대로)
[V3 딥다이브] "진짜 범인" 찾기: DB 락(가설 A) vs GC Hell(가설 B)

"DB 락"을 "가설 A"로 "추정"했다.
"하지만" 16ms "초고속 로그(데이터)"가 "가설 A"를 "반박"했다.
**"데이터"**로 "가설 A"를 "폐기"하고 "GC Hell(가설 B)"을 "확정"했다.
3. "The Grand Finale" (README "결론"에 "무조건" 쓸 고민)
이 "고민"들이야말로, 님이 "V4"에서 "한 걸음 더" 나아간 "시니어"의 "아키텍처" 고민을 보여줍니다. 이것들은 README의 "본문"이 아닌, **"별도의 5번 챕터"**로 "분리"해야 합니다.

"README" 5번 챕터 (최종 템플릿)
(V1~V4 튜닝 여정이 "끝난" 후)
5. 🚀 튜닝 여정 이후 (Trade-offs & Next Steps)
V4(GC 튜닝)로 Error 0.0%와 TPS 5,000+를 달성했지만, 이는 "INSERT 병목"을 해결했을 뿐, "완벽한" 아키텍처는 아닙니다. V4가 "해결"한 문제와, "새롭게" 드러난 "Trade-off" 및 "다음 단계"입니다.

(1) Trade-off: "로그 유실" (In-Memory Queue의 한계)
[V4의 치명적 한계] V4가 사용한 BlockingQueue는 100% "In-Memory(RAM)"입니다.
[문제 상황] 만약 "요리사(5000 TPS)"가 "카운터(1573 TPS)"보다 "잠깐" 느려져서 큐에 "3,000개"가 쌓인 "순간", "V4 서버가 '다운'된다면?"
[결과] "RAM"에 있던 "로그 3,000개"는 **"영원히 유실(Data Loss)"**됩니다.
[다음 단계 (V5): 유실 방지] "로그 유실이 절대 안 된다"는 "비즈니스 요구사항"이 있다면, "큐"를 "서버(RAM)" 안이 아닌, "서버 밖"의 "안전한(Disk-Based)" 전문 "물류 창고"로 "외주"를 줘야 합니다.
➔ Kafka / RabbitMQ / Redis (Persistence) 도입의 "필요성"이 "증명"됩니다.
(2) "새로운 병목": DELETE (DB 최적화)
V4는 INSERT만 해결했습니다. "로그"는 "삭제(DELETE)"가 "진짜" 병목입니다.

[V6의 문제] 로그가 "10억 건" 쌓였을 때, "오래된" 로그를 지우기 위해 DELETE FROM log WHERE ... 쿼리를 실행하면, "V1(즉사)" 때보다 "더 끔찍한" **"DB 락(Lock)"**이 발생하여 "서버 전체"가 "즉사"합니다.
[해결책 1: 인덱스 최소화] "조회"가 없는 ip_address 등의 "불필요한" 인덱스를 "전부 제거"해서, INSERT 속도를 "추가로" 높이고 "DB 용량"을 아낍니다.
[해결책 2: 파티셔닝 (Partitioning)] "DB 락" 없이 "0.1초" 만에 "삭제"하는 "유일한" 방법입니다.
"로그 테이블"을 "날짜별"로 "미리 쪼개"둡니다. (e.g., PARTITION BY RANGE (TO_DAYS(created_at)))
"오래된" 파티션(e.g., log_2025_10_01)을 DROP PARTITION 명령어로 "삭제"합니다.
결과: "DB 락" 없이, "물리적"으로 "파일"을 "삭제"하므로 "0.1초" 만에 "1억 건" 삭제가 "완료"됩니다.
결론 (깊이): "Kafka(V5)"나 "파티셔닝(V6)"을 "구현"할 필요는 1%도 없습니다.

님의 V4가 "GC Hell"은 해결했지만, "로그 유실"과 "DELETE 병목"이라는 "새로운" 문제를 "남겼다"는 것을 **"인지"**하고, 그 "해결책"으로 "Kafka"와 "파티셔닝"을 "제시"하는 것,

거기까지가 "주니어"가 보여줄 수 있는 "가장 깊고" "매력적인" README.md의 "결말"입니다

5. 🚀 튜닝 여정 이후 (Trade-offs & Next Steps)
V4(GC 튜닝)로 Error 0.0%와 TPS 5,000+를 달성했지만, 100% "완벽한" 시스템은 없습니다. V4가 "여전히" 안고 있는 "Trade-off"와 "다음" 병목입니다.

1. Trade-off: "V1 ➔ V4로 바로 가면 안 됐나?"
"정답"은 없습니다. "V1 ➔ V4(String)"는 **"코드"**로 "GC"까지 튜닝한 "백엔드 개발자"의 "최적화"입니다.
"V1 ➔ V2(큐)"에서 멈추는 것은, "GC Hell(Error 2.0%)"을 방치한 "미완성"입니다.
"V1 ➔ V3(배치)"에서 멈추는 것은, "GC Hell(Error 0.9%)"의 "진짜" 원인을 "데이터"로 파고들지 못한 "타협"입니다.
결론: V4는 "현실적인(RDB)" 제약 하에서 "Error 0.0%"를 달성하기 위한 "논리적인" 최종 단계였습니다.
2. Trade-off: "기업 상황별 의사결정"
(비용 중시): V4(String 튜닝)는 "서버 증설(돈)" 없이 "코드(무료)"로 "GC"까지 튜닝했으므로, "가장 비용 효율적인" 해결책입니다.
(응답 속도 중시): V4는 "카운터(API)"와 "요리사(DB)"가 "같은 JVM"에 있어 "GC"가 "서로" 영향을 줍니다. "응답 속도(P99)"가 1ms라도 중요한 "광고/금융" 서비스라면, "3번(Kafka)"으로 가야 합니다.
3. "Next Step": "로그 유실" (In-Memory Queue의 한계)
[치명적인 문제] 님의 "V4"는 Error 0.0%를 달성했지만, "치명적인" 한계가 있습니다.
BlockingQueue는 "In-Memory(RAM)"입니다.
만약 "요리사(5000 TPS)"가 "카운터(1573 TPS)"보다 "잠깐" 느려져서 큐에 "3,000개"가 쌓인 "순간", "V4 서버가 '다운'된다면?"
결과: "RAM"에 있던 "로그 3,000개"는 "디스크(DB)"에 닿아보지도 못하고 **"영원히 유실(Data Loss)"**됩니다.
"진짜" 해결책 (V5): "큐"를 "서버(RAM)" 안이 아닌, "서버 밖"의 "안전한(Disk-Based)" 전문 "물류 창고"로 "외주"를 줘야 합니다.
➔ Kafka / RabbitMQ / AWS SQS 도입의 "필요성"이 "증명"됩니다.
결론 (깊이): "Kafka(V5)"를 "구현"할 필요는 1%도 없습니다. 님의 V4가 "GC Hell"은 해결했지만 "로그 유실"이라는 "새로운" 문제를 "남겼다"는 것을 **"인지"**하고, 그 "해결책"으로 "Kafka"를 "제시"하는 것, 거기까지가 "주니어"가 보여줄 수 있는 "가장 깊고" "매력적인" README.md의 "결말"입니다.
===========================
" README.md"에 "딥다이브"를 담는 "골든 키": <details>
"딥다이브(Deep-Dive)"는 숨겨야 합니다. README.md가 "깔끔"해 보이면서도, "궁금한" 사람(시니어/면접관)은 "클릭"해서 볼 수 있게 만드는 "마법의" Markdown 태그, **<details> (접기/펼치기)**를 사용해야 합니다.

[예시] 님의 "V1 핫스팟" 비유를 README.md에 이렇게 적용합니다.


... V1의 nGrinder 테스트 결과, TPS 24, Error 80%라는 "즉사" 수준의 결과를 확인했습니다.

<details> <summary><b>[V1 딥다이브] "왜" INSERT가 SELECT까지 마비시켰는가? (핫스팟 분석)</b></summary>

V1의 "연쇄 붕괴"는 "DB 커넥션 풀" 고갈이 "현상"일 뿐, "근본 원인"은 RDB의 AUTO_INCREMENT PK가 유발하는 **"B-Tree 인덱스 핫스팟"**이었습니다.

핫스팟 발생: INSERT가 DB 인덱스(B-Tree)의 마지막 리프 노드 페이지("1번 화구")에 몰림
락 점유: "사장님 1"이 "1번 화구"(Lock)를 잡고 요리를 시작
커넥션 고갈: "사장님 2~10"은 락이 풀리길 기다리며 DB 커넥션(냄비) 을 쥔 채 대기
커넥션 풀 소진: "냄비 선반(DB 커넥션 풀)"은 0/10 상태로 고갈
연쇄 붕괴 시작: INSERT와 무관한 SELECT API("샐러드 손님") 도착
결과: INSERT의 병목이 SELECT까지 마비시키는 연쇄 붕괴 발생
</details>

... V1의 "동기" 방식이 "핫스팟" 문제를 "증폭"시킨다고 판단, "결합 분리(Decoupling)"를 위해 V2(비동기 큐)를 도입했습니다.


2. 님의 "전체 여정"을 담는 README.md (최종 템플릿)
님이 V1(즉사) ➔ V2(GC Hell 2.0%) ➔ V3(GC Hell 0.9%) ➔ V4(Error 0.0%)까지 겪은 "모든" "데이터"와 "가설 검증(혼란)"을 **"하나의 완벽한 스토리"**로 만드는 템플릿입니다.

1. 프로젝트명: 대용량 트래픽 로깅 시스템의 병목 현상 분석 및 튜닝
(nGrinder VUser 500명, 1분간) "RDB(MySQL)"를 사용하는 레거시 시스템이 INSERT 병목으로 인해 "즉사(V1)"하는 문제를 V4까지 "데이터"에 기반하여 점진적으로 튜닝하고 "해결"한 프로젝트입니다.

2. 📊 최종 튜닝 결과 (V1 vs V4)
버전	아키텍처	Mean TPS (처리량)	Error Rate	비고
V1	동기 + save()	24.1	80.5%	"서버 즉사"
V2	비동기 + Queue	1,261.8	2.0%	"GC Hell" (큐 폭증)
V3	Queue + Batch	1,573.3	0.9%	"GC Hell" (가끔 멈춤)
V4	V3 + GC 튜닝 (String)	5,000+	0.0%	"최종 해결"
3. 🚗 튜닝 여정 (The Journey: V1 ➔ V4)
"Error 80.5%"에서 "Error 0.0%"에 도달하기까지, "새로운" 병목을 "데이터"로 발견하고 "가설"을 검증하며 해결한 "전체 과정"입니다.

1️⃣ V1: 동기 처리 (즉사) - 문제 정의
nGrinder (VUser 500): [V1의 "즉사" nGrinder 그래프 이미지]
분석: TPS 24, Error 80.5%. "카운터(톰캣 스레드)"가 "느린" DB 작업(save)을 "동기"로 기다리면서, "커넥션 풀"과 "스레드 풀"이 "전부" 고갈되어 SELECT API까지 마비되는 "연쇄 붕괴" 발생.
<details> <summary><b>[V1 딥다이브] "왜" INSERT가 SELECT까지 마비시켰는가? (핫스팟 분석)</b></summary>

(님은 이 "핫스팟"을 V3에서 "가짜 보스"로 폐기했지만, V1의 "가장 유력한" 용의자로 "기록"하는 것은 100% 옳습니다.)

핫스팟 발생: INSERT가 AUTO_INCREMENT PK의 마지막 페이지("1번 화구")에 몰림
락 점유 및 커넥션 고갈: ... (님의 "핫스팟" 비유) ...
결과: INSERT의 병목이 SELECT까지 마비시킴.
</details>

2️⃣ V2: 비동기 (Queue) - 1차 해결 (그러나 "새로운" 병목)
nGrinder (VUser 500): [V2의 "Error 2.0%" nGrinder 그래프 이미지]
분석: TPS 1,261, Error 2.0%. "비동기(Queue)"로 "서버 즉사(V1)"는 막았지만, "Error 2.0%" (Client-Side Timeout)가 발생.
원인: "요리사(소비자, 142 TPS)"가 "카운터(생산자, 1261 TPS)"보다 "압도적으로" 느려서, "큐(RAM)"가 7만 개씩 쌓이며 "GC Hell (Stop-the-World)" 발생.
<details> <summary><b>[V2 딥다이브] "GC Hell"이 "Error 2.0%"를 유발한 원리</b></summary>

큐 폭증: "요리사(142)"가 느려 "큐(RAM)"에 DTO 객체 9만 개가 쌓임.
Stop-the-World: "매니저(JVM)"가 "RAM"이 터질까 봐 **"모두 멈춰!(Stop-the-World)"**를 외치고 "0.3초"간 "대청소(Full GC)" 시작.
Timeout 발생: "GC"가 터진 "0.3초" 동안 "카운터(톰캣 스레드)"도 **"얼음"**이 됨.
결과: "손님(nGrinder)"이 "0.1초"간 응답이 없자 "전화를 끊어버림(Timeout)". 이것이 Error 2.0%의 "진짜" 원인.
</details>

3️⃣ V3: Queue + Batch - "진짜 범인"을 찾아서
nGrinder (VUser 500): [V3의 "Error 0.9%" nGrinder 그래프 이미지]
분석: TPS 1,573, Error 0.9%. V2(142 TPS) ➔ V3(4000+ TPS)로 "요리사"는 "압도적으로" 빨라졌음. "그런데도" Error 0.9%와 "250ms 멈춤 로그"가 "가끔" 발생.
<details> <summary><b>[V3 딥다이브] "진짜 범인" 찾기: DB 락(가설 A) vs GC Hell(가설 B)</b></summary>

가설 A (폐기): "DB 락"이 범인인가?

54개=260ms, 377개=255ms "이상치" 로그 2개를 발견.
"요리 개수"와 상관없이 "0.25초"가 걸리는 것을 보고 "DB 락(핫스팟)"을 "1차" 용의자로 "추정"함.
가설 B (확정): "GC Hell"이 범인이다.

"반박 증거": 19개=5ms, 80개=16ms 등 "99%"의 "초고속" 로그를 발견.
"가설 A 폐기": "DB 락"이 범인이었다면 "16ms"는 "절대" 불가능. **"데이터"**로 "가설 A"를 **"폐기"**함.
"최종 결론": "요리사(4000+)"가 "카운터(1573)"보다 "압도적으로" 빠른데도, "요리사"와 "카운터"가 "동시에" 0.25초씩 "가끔" 멈추는 "범인"은 **"GC Hell"**이 "유일"함.
</details>

4️⃣ V4: GC 튜닝 (DTO ➔ String) - 최종 해결
진단: V3의 "GC Hell"은 "큐"가 쌓여서가 아니라, "카운터"와 "요리사"가 1초에 수천 개의 "무거운 DTO(쓰레기)"를 만들고 버려서 "GC(대청소)"가 "너무 자주" 터진 것이 "원인"임을 "확정"함.
해결: "JVM 옵션(DevOps)"이 아닌, "백엔드 개발자"로서 "코드"를 수정함.
"카운터"와 "요리사" 사이의 "약속(큐)"을 BlockingQueue<LogDataDto> (무거운 컵) ➔ BlockingQueue<String> (가벼운 냅킨)으로 변경.
증명: jstat (JVM 감시 카메라)로 V4 테스트 시, "Stop-the-World"를 유발하는 FGC (Full GC 횟수)가 0을 유지함을 "증명"함.
nGrinder (VUser 500): [V4의 "Error 0.0%" 최종 nGrinder 그래프 이미지]
결과: Error 0.0%, TPS 5,000+ 달성.
4. 🚀 핵심 학습 및 결론 (Key Takeaways)
"데이터"는 "가설"보다 강하다: "V3" 로그 분석 시 "DB 락(가설 A)"이라는 "성급한" 추측을 했으나, 16ms "초고속 로그(데이터)"를 "반박 증거"로 찾아내 "가설 A"를 "폐기"하고 "GC Hell(가설 B)"이라는 "진짜" 원인을 찾음.
"병목"은 "연쇄적"이다: V1(핫스팟) ➔ V2(소비자 속도) ➔ V3(GC Hell)
"GC Hell" 튜닝의 "핵심": "GC(청소부)"를 튜닝하는 것보다, "GC"가 "일할 필요가 없도록" "쓰레기(객체 생성)" 자체를 줄이는 "애플리케이션(코드)" 튜닝이 더 "근본적인" 해결책임을 "증명"함

================================

## 5️⃣ 해결 방법 — 솔루션  C: kafka
방문기록처럼 유실되도 데이터가 아니라
금융기록처럼 유실되는 절대 안되는 데이터라면? 

## 기타 
1. 테이블 스키마에 대한 고민

2. 기업간 상황속에서 의 trade-off
- 처리속도
- 응답속도가 최우선으로 중요한다면
- 비용이 최우선으로 중요시한다면

빈 생성주기 postcontruct
캐싱
redis
## 6️⃣ Trade-off 분석 및 아키텍처 결정 - A B C
